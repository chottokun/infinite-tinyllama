target_task: tasks/nlp/sentiment-analysis.md
base_model_id: TinyLlama/TinyLlama-1.1B-intermediate-step-480k-1T
model_name: tinyllama-sentiment-analyzer-en-v0.1
output_base_dir: /data/output
dataset_id: carblacac/twitter-sentiment-analysis
dataset_input_field_name: text
dataset_output_field_name: feeling
dataset_output_field_values_to_texts:
  0: "Negative"
  1: "Positive"
dataset_train_split_seed: 42
dataset_train_split_test_size: 0.2
lora_r: 8
lora_alpha: 16
lora_dropout: 0.05
train_claim_gpu_num: 1
train_per_device_train_batch_size: 16
train_gradient_accumulation_steps: 4
train_num_train_epochs: 4
train_max_steps: 1000
train_fp16: True
inference_max_new_tokens: 16
evaluations:
  -
    prompt: "Yes my laptop works So now i can abort my diplomthesis"
    expected_output: "Negative"
  -
    prompt: "Hmm don't know what to do today -- Model just canceled = I hate it when that happens..will have to do gardening!	"
    expected_output: "Negative"
  -
    prompt: "About to go to bed. Sleeping really late tomorrow! I am so glad the Tigers won tonight!!"
    expected_output: "Positive"
  -
    prompt: "AHH i'm so HAPPY. I just found my ipod. God is sooo good to me!"
    expected_output: "Positive"
